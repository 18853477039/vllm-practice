{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Collecting llmcompressor\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/9c/dd/953e05c25aed8a92355688bf118e9a5327b9a257a7d69ae5ac6ffcbf4af3/llmcompressor-0.4.1-py3-none-any.whl (255 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.1/255.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting loguru (from llmcompressor)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/0c/29/0348de65b8cc732daa3e33e67806420b2ae89bdce2b04af740289c5c6c8c/loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.0.0 in /root/miniconda3/lib/python3.12/site-packages (from llmcompressor) (6.0.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.0 in /root/miniconda3/lib/python3.12/site-packages (from llmcompressor) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.0.0 in /root/miniconda3/lib/python3.12/site-packages (from llmcompressor) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.0.0 in /root/miniconda3/lib/python3.12/site-packages (from llmcompressor) (4.67.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1.2 in /root/miniconda3/lib/python3.12/site-packages (from llmcompressor) (8.1.8)\n",
      "Requirement already satisfied: torch>=1.7.0 in /root/miniconda3/lib/python3.12/site-packages (from llmcompressor) (2.5.1)\n",
      "Requirement already satisfied: transformers<5.0,>4.0 in /root/miniconda3/lib/python3.12/site-packages (from llmcompressor) (4.49.0)\n",
      "Requirement already satisfied: datasets in /root/miniconda3/lib/python3.12/site-packages (from llmcompressor) (3.3.2)\n",
      "Requirement already satisfied: accelerate!=1.1.0,>=0.20.3 in /root/miniconda3/lib/python3.12/site-packages (from llmcompressor) (1.5.1)\n",
      "Collecting pynvml (from llmcompressor)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/ed/df/f7cf07a65a96dd11d71f346f9c2863accdd4784da83af7181b067d556cbc/pynvml-12.0.0-py3-none-any.whl (26 kB)\n",
      "Collecting compressed-tensors==0.9.2 (from llmcompressor)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/bb/6e/dc0a80ce14802344e3f4d0520285e8773b83ec2fd864e7cab886718f55a9/compressed_tensors-0.9.2-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic>=2.0 in /root/miniconda3/lib/python3.12/site-packages (from compressed-tensors==0.9.2->llmcompressor) (2.10.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/lib/python3.12/site-packages (from accelerate!=1.1.0,>=0.20.3->llmcompressor) (23.2)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/lib/python3.12/site-packages (from accelerate!=1.1.0,>=0.20.3->llmcompressor) (5.9.8)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /root/miniconda3/lib/python3.12/site-packages (from accelerate!=1.1.0,>=0.20.3->llmcompressor) (0.29.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /root/miniconda3/lib/python3.12/site-packages (from accelerate!=1.1.0,>=0.20.3->llmcompressor) (0.5.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/lib/python3.12/site-packages (from requests>=2.0.0->llmcompressor) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/lib/python3.12/site-packages (from requests>=2.0.0->llmcompressor) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/lib/python3.12/site-packages (from requests>=2.0.0->llmcompressor) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.12/site-packages (from requests>=2.0.0->llmcompressor) (2024.2.2)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.7.0->llmcompressor) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.7.0->llmcompressor) (4.12.2)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.7.0->llmcompressor) (3.3)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.7.0->llmcompressor) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.7.0->llmcompressor) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.7.0->llmcompressor) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.7.0->llmcompressor) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.7.0->llmcompressor) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.7.0->llmcompressor) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.7.0->llmcompressor) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.7.0->llmcompressor) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.7.0->llmcompressor) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.7.0->llmcompressor) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.7.0->llmcompressor) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.7.0->llmcompressor) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.7.0->llmcompressor) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.7.0->llmcompressor) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.7.0->llmcompressor) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.7.0->llmcompressor) (76.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.7.0->llmcompressor) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.7.0->llmcompressor) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/lib/python3.12/site-packages (from transformers<5.0,>4.0->llmcompressor) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/miniconda3/lib/python3.12/site-packages (from transformers<5.0,>4.0->llmcompressor) (0.21.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /root/miniconda3/lib/python3.12/site-packages (from datasets->llmcompressor) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /root/miniconda3/lib/python3.12/site-packages (from datasets->llmcompressor) (0.3.8)\n",
      "Requirement already satisfied: pandas in /root/miniconda3/lib/python3.12/site-packages (from datasets->llmcompressor) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /root/miniconda3/lib/python3.12/site-packages (from datasets->llmcompressor) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /root/miniconda3/lib/python3.12/site-packages (from datasets->llmcompressor) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /root/miniconda3/lib/python3.12/site-packages (from datasets->llmcompressor) (3.11.13)\n",
      "Collecting nvidia-ml-py<13.0.0a0,>=12.0.0 (from pynvml->llmcompressor)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/d8/a8/ec37169be4e2b7063b9076ed3fe0661e87335fbca665eed3f48c415cb234/nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /root/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets->llmcompressor) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets->llmcompressor) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets->llmcompressor) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets->llmcompressor) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets->llmcompressor) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets->llmcompressor) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets->llmcompressor) (1.18.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/miniconda3/lib/python3.12/site-packages (from pydantic>=2.0->compressed-tensors==0.9.2->llmcompressor) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /root/miniconda3/lib/python3.12/site-packages (from pydantic>=2.0->compressed-tensors==0.9.2->llmcompressor) (2.27.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/lib/python3.12/site-packages (from jinja2->torch>=1.7.0->llmcompressor) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/lib/python3.12/site-packages (from pandas->datasets->llmcompressor) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/lib/python3.12/site-packages (from pandas->datasets->llmcompressor) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/lib/python3.12/site-packages (from pandas->datasets->llmcompressor) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets->llmcompressor) (1.16.0)\n",
      "Installing collected packages: nvidia-ml-py, pynvml, loguru, compressed-tensors, llmcompressor\n",
      "  Attempting uninstall: compressed-tensors\n",
      "    Found existing installation: compressed-tensors 0.9.1\n",
      "    Uninstalling compressed-tensors-0.9.1:\n",
      "      Successfully uninstalled compressed-tensors-0.9.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "vllm 0.7.3 requires compressed-tensors==0.9.1, but you have compressed-tensors 0.9.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed compressed-tensors-0.9.2 llmcompressor-0.4.1 loguru-0.7.3 nvidia-ml-py-12.570.86 pynvml-12.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install llmcompressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19034502bae1d7b",
   "metadata": {},
   "source": [
    "### Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3170c095eb36baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cba20460b7a42a39efcf2b436a05ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "MODEL_ID = \"/root/autodl-fs/data2/anti_fraud/models/modelscope/hub/hub/Qwen/Qwen2-7B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID, device_map=\"auto\", torch_dtype=\"auto\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7bfbd60029dbc",
   "metadata": {},
   "source": [
    "### Preparing Calibration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f04ac9d-8dc7-4abf-8ba1-a7472a237269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91972af9a3dfef80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb94b8b0d2f46378149a64b4e9e6cbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.90k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686b4a1e17f843d495885bffc000479a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00003-a3ecf92756993583.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad2aef8924244edbe278ac50b907dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00001-of-00003-0a1804bcb6ae68c6.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7208a477b92a4aa485717e7edd401579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00002-of-00003-ee46ed25cfae92c6.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7202898c8a4e85bdd0a9317b71a146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-f7dfac4afe5b93f4.parquet:   0%|          | 0.00/81.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec0b3c858ce41c69ff4a4763a354217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00003-a6c9fb894be3e50b.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad97e80f4cef4c099256032142d3634b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00001-of-00003-d6a0402e417f35ca.parquet:   0%|          | 0.00/243M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af5f605adcc84e9bbe6b351e2ccf49c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00002-of-00003-c0db75b92a2f48fd.parquet:   0%|          | 0.00/243M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a231edd29b4f4cb8a4b41eabc7ff3b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-3d4cd8309148a71f.parquet:   0%|          | 0.00/80.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ccd13007b54747a1032d8c8d7493b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_sft split:   0%|          | 0/207865 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b6035bd4fd41fa9f8ab47d88eb7030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_sft split:   0%|          | 0/23110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c931d3ad7aa447d8ffcc433b420208e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_gen split:   0%|          | 0/256032 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348d8bf426974f10a77a78c7e75c10ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_gen split:   0%|          | 0/28304 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ed6de127044eb0a3d951df4d462768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad20011a9595494db97b1faf02d0d21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "NUM_CALIBRATION_SAMPLES = 512\n",
    "MAX_SEQUENCE_LENGTH = 2048\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "# TODO use chinese dataset\n",
    "ds = load_dataset(\"HuggingFaceH4/ultrachat_200k\", split=\"train_sft\")\n",
    "ds = ds.shuffle(seed=42).select(range(NUM_CALIBRATION_SAMPLES))\n",
    "\n",
    "def preprocess(example):\n",
    "    return {\"text\": tokenizer.apply_chat_template(example[\"messages\"], tokenize=False)}\n",
    "ds = ds.map(preprocess)\n",
    "\n",
    "def tokenize(sample):\n",
    "    return tokenizer(sample[\"text\"], padding=False, max_length=MAX_SEQUENCE_LENGTH, truncation=True, add_special_tokens=False)\n",
    "ds = ds.map(tokenize, remove_columns=ds.column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6aec571fb8e9f8",
   "metadata": {},
   "source": [
    "### Applying Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11489231bd209ea5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:44:06.463755+0800 | main | WARNING - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False\n",
      "2025-03-14T12:44:06.466857+0800 | main | INFO - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_oneshot=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=None,\n",
      "eval_strategy=IntervalStrategy.NO,\n",
      "eval_use_gather_object=False,\n",
      "evaluation_strategy=None,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./output/runs/Mar14_12-44-06_autodl-container-34fb1182ae-faaacbaf,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=OptimizerNames.ADAMW_TORCH,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=./output,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./output,\n",
      "run_stages=False,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=SaveStrategy.STEPS,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "2025-03-14T12:44:06.934554+0800 | _check_create_state | INFO - State created for compression lifecycle\n",
      "2025-03-14T12:44:06.938213+0800 | pre_initialize_structure | INFO - Compression lifecycle structure pre-initialized for 0 modifiers\n",
      "2025-03-14T12:44:06.940485+0800 | pre_initialize_structure | INFO - Compression lifecycle structure pre-initialized for 0 modifiers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:44:06.954450+0800 | one_shot | INFO - *** One Shot ***\n",
      "2025-03-14T12:44:06.962598+0800 | from_modifiers | INFO - Creating recipe from modifiers\n",
      "2025-03-14T12:44:07.000031+0800 | _check_compile_recipe | INFO - Recipe compiled and 1 modifiers created\n",
      "2025-03-14T12:44:07.000970+0800 | _infer_mappings_from_model | INFO - No SmoothQuantModifier.mappings provided, inferring from model...\n",
      "2025-03-14T12:44:07.976885+0800 | _calibrate | INFO - Running SmoothQuantModifier calibration with 512 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:52<00:00,  9.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:45:00.351688+0800 | _apply_smoothing | INFO - Smoothing activation scales...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:45:00.551662+0800 | on_initialize_structure | WARNING - GPTQ quantization is set to True without an active quantization modifier.\n",
      "2025-03-14T12:45:00.552593+0800 | _build_quant_modifier | INFO - Building quantization modifier with args: {'targets': 'Linear', 'scheme': 'W8A8', 'ignore': ['lm_head']}\n",
      "2025-03-14T12:45:00.582753+0800 | _check_calibration_data | INFO - Skipping QuantizationModifier calibration, it is not required for the provided quantization config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing intermediates cache: 100%|██████████| 512/512 [00:00<00:00, 714.36it/s]\n",
      "(1/29): Calibrating: 100%|██████████| 512/512 [00:30<00:00, 16.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:45:32.382909+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.0.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:45:34.215049+0800 | compress | METRIC - time 1.83s\n",
      "2025-03-14T12:45:34.217457+0800 | compress | METRIC - error 55.28\n",
      "2025-03-14T12:45:34.219631+0800 | compress | METRIC - GPU 0 | usage: 25.86% | total memory: 85 GB\n",
      "2025-03-14T12:45:34.220615+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T12:45:34.221700+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.0.self_attn.k_proj using 512 samples\n",
      "2025-03-14T12:45:35.342784+0800 | compress | METRIC - time 1.12s\n",
      "2025-03-14T12:45:35.344348+0800 | compress | METRIC - error 6.69\n",
      "2025-03-14T12:45:35.345446+0800 | compress | METRIC - GPU 0 | usage: 25.86% | total memory: 85 GB\n",
      "2025-03-14T12:45:35.346511+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:45:35.348842+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.0.self_attn.v_proj using 512 samples\n",
      "2025-03-14T12:45:36.661451+0800 | compress | METRIC - time 1.31s\n",
      "2025-03-14T12:45:36.663078+0800 | compress | METRIC - error 0.50\n",
      "2025-03-14T12:45:36.664858+0800 | compress | METRIC - GPU 0 | usage: 25.86% | total memory: 85 GB\n",
      "2025-03-14T12:45:36.665613+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:45:36.667130+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.0.self_attn.o_proj using 512 samples\n",
      "2025-03-14T12:45:38.037157+0800 | compress | METRIC - time 1.37s\n",
      "2025-03-14T12:45:38.039084+0800 | compress | METRIC - error 1.56\n",
      "2025-03-14T12:45:38.040804+0800 | compress | METRIC - GPU 0 | usage: 25.86% | total memory: 85 GB\n",
      "2025-03-14T12:45:38.041365+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T12:45:38.042479+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.0.mlp.gate_proj using 512 samples\n",
      "2025-03-14T12:45:39.449590+0800 | compress | METRIC - time 1.41s\n",
      "2025-03-14T12:45:39.451281+0800 | compress | METRIC - error 478.63\n",
      "2025-03-14T12:45:39.452734+0800 | compress | METRIC - GPU 0 | usage: 25.86% | total memory: 85 GB\n",
      "2025-03-14T12:45:39.453407+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:45:39.454391+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.0.mlp.up_proj using 512 samples\n",
      "2025-03-14T12:45:40.839336+0800 | compress | METRIC - time 1.38s\n",
      "2025-03-14T12:45:40.841001+0800 | compress | METRIC - error 16.84\n",
      "2025-03-14T12:45:40.842775+0800 | compress | METRIC - GPU 0 | usage: 25.86% | total memory: 85 GB\n",
      "2025-03-14T12:45:40.843547+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:45:40.845078+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.0.mlp.down_proj using 512 samples\n",
      "2025-03-14T12:45:48.126899+0800 | compress | METRIC - time 7.28s\n",
      "2025-03-14T12:45:48.129937+0800 | compress | METRIC - error 2.43\n",
      "2025-03-14T12:45:48.130583+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:45:48.130913+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(1/29): Propagating: 100%|██████████| 512/512 [00:06<00:00, 81.05it/s]\n",
      "(2/29): Calibrating: 100%|██████████| 512/512 [00:32<00:00, 15.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:46:26.799923+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.1.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:46:28.059322+0800 | compress | METRIC - time 1.26s\n",
      "2025-03-14T12:46:28.060574+0800 | compress | METRIC - error 49.35\n",
      "2025-03-14T12:46:28.062255+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:46:28.062988+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T12:46:28.064417+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.1.self_attn.k_proj using 512 samples\n",
      "2025-03-14T12:46:29.159680+0800 | compress | METRIC - time 1.09s\n",
      "2025-03-14T12:46:29.161217+0800 | compress | METRIC - error 13.56\n",
      "2025-03-14T12:46:29.162915+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:46:29.163673+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:46:29.165152+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.1.self_attn.v_proj using 512 samples\n",
      "2025-03-14T12:46:30.273928+0800 | compress | METRIC - time 1.11s\n",
      "2025-03-14T12:46:30.275455+0800 | compress | METRIC - error 0.52\n",
      "2025-03-14T12:46:30.276547+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:46:30.277396+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:46:30.279334+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.1.self_attn.o_proj using 512 samples\n",
      "2025-03-14T12:46:31.436566+0800 | compress | METRIC - time 1.16s\n",
      "2025-03-14T12:46:31.438081+0800 | compress | METRIC - error 0.31\n",
      "2025-03-14T12:46:31.440018+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:46:31.440836+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T12:46:31.442708+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.1.mlp.gate_proj using 512 samples\n",
      "2025-03-14T12:46:32.820713+0800 | compress | METRIC - time 1.38s\n",
      "2025-03-14T12:46:32.822395+0800 | compress | METRIC - error 5710.75\n",
      "2025-03-14T12:46:32.824070+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:46:32.824825+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:46:32.826283+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.1.mlp.up_proj using 512 samples\n",
      "2025-03-14T12:46:34.220676+0800 | compress | METRIC - time 1.39s\n",
      "2025-03-14T12:46:34.222202+0800 | compress | METRIC - error 352.12\n",
      "2025-03-14T12:46:34.223894+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:46:34.224618+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:46:34.226468+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.1.mlp.down_proj using 512 samples\n",
      "2025-03-14T12:46:41.590641+0800 | compress | METRIC - time 7.36s\n",
      "2025-03-14T12:46:41.594518+0800 | compress | METRIC - error 3.01\n",
      "2025-03-14T12:46:41.596089+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:46:41.596755+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(2/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 144.16it/s]\n",
      "(3/29): Calibrating: 100%|██████████| 512/512 [00:32<00:00, 15.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:47:17.367342+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.2.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:47:18.867027+0800 | compress | METRIC - time 1.50s\n",
      "2025-03-14T12:47:18.869112+0800 | compress | METRIC - error 119.28\n",
      "2025-03-14T12:47:18.870739+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:47:18.871437+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T12:47:18.872803+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.2.self_attn.k_proj using 512 samples\n",
      "2025-03-14T12:47:19.985461+0800 | compress | METRIC - time 1.11s\n",
      "2025-03-14T12:47:19.987171+0800 | compress | METRIC - error 33.55\n",
      "2025-03-14T12:47:19.988781+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:47:19.989544+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:47:19.990903+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.2.self_attn.v_proj using 512 samples\n",
      "2025-03-14T12:47:21.137716+0800 | compress | METRIC - time 1.15s\n",
      "2025-03-14T12:47:21.139444+0800 | compress | METRIC - error 1.85\n",
      "2025-03-14T12:47:21.140444+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:47:21.141237+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:47:21.143402+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.2.self_attn.o_proj using 512 samples\n",
      "2025-03-14T12:47:22.316546+0800 | compress | METRIC - time 1.17s\n",
      "2025-03-14T12:47:22.318553+0800 | compress | METRIC - error 0.69\n",
      "2025-03-14T12:47:22.320167+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:47:22.320871+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T12:47:22.321770+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.2.mlp.gate_proj using 512 samples\n",
      "2025-03-14T12:47:23.715070+0800 | compress | METRIC - time 1.39s\n",
      "2025-03-14T12:47:23.716549+0800 | compress | METRIC - error 9170.53\n",
      "2025-03-14T12:47:23.717173+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:47:23.717486+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:47:23.718069+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.2.mlp.up_proj using 512 samples\n",
      "2025-03-14T12:47:25.124698+0800 | compress | METRIC - time 1.41s\n",
      "2025-03-14T12:47:25.126575+0800 | compress | METRIC - error 477.66\n",
      "2025-03-14T12:47:25.127599+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:47:25.128391+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:47:25.130253+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.2.mlp.down_proj using 512 samples\n",
      "2025-03-14T12:47:32.822213+0800 | compress | METRIC - time 7.69s\n",
      "2025-03-14T12:47:32.826313+0800 | compress | METRIC - error 5.82\n",
      "2025-03-14T12:47:32.827906+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:47:32.828605+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(3/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 166.22it/s]\n",
      "(4/29): Calibrating: 100%|██████████| 512/512 [00:32<00:00, 15.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:48:08.198056+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.3.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:48:09.475376+0800 | compress | METRIC - time 1.28s\n",
      "2025-03-14T12:48:09.477127+0800 | compress | METRIC - error 122.86\n",
      "2025-03-14T12:48:09.478883+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:48:09.479631+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T12:48:09.481095+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.3.self_attn.k_proj using 512 samples\n",
      "2025-03-14T12:48:10.583434+0800 | compress | METRIC - time 1.10s\n",
      "2025-03-14T12:48:10.585202+0800 | compress | METRIC - error 41.19\n",
      "2025-03-14T12:48:10.586630+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:48:10.587190+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:48:10.588267+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.3.self_attn.v_proj using 512 samples\n",
      "2025-03-14T12:48:11.717085+0800 | compress | METRIC - time 1.13s\n",
      "2025-03-14T12:48:11.720544+0800 | compress | METRIC - error 4.81\n",
      "2025-03-14T12:48:11.721562+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:48:11.722820+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:48:11.723854+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.3.self_attn.o_proj using 512 samples\n",
      "2025-03-14T12:48:12.905313+0800 | compress | METRIC - time 1.18s\n",
      "2025-03-14T12:48:12.907056+0800 | compress | METRIC - error 2.04\n",
      "2025-03-14T12:48:12.908123+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:48:12.908875+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T12:48:12.910971+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.3.mlp.gate_proj using 512 samples\n",
      "2025-03-14T12:48:14.551433+0800 | compress | METRIC - time 1.64s\n",
      "2025-03-14T12:48:14.553288+0800 | compress | METRIC - error 6116.95\n",
      "2025-03-14T12:48:14.554289+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:48:14.555462+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:48:14.556411+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.3.mlp.up_proj using 512 samples\n",
      "2025-03-14T12:48:15.995358+0800 | compress | METRIC - time 1.44s\n",
      "2025-03-14T12:48:15.997439+0800 | compress | METRIC - error 1224.91\n",
      "2025-03-14T12:48:15.998613+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:48:15.999219+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:48:16.000515+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.3.mlp.down_proj using 512 samples\n",
      "2025-03-14T12:48:23.279645+0800 | compress | METRIC - time 7.28s\n",
      "2025-03-14T12:48:23.284062+0800 | compress | METRIC - error 8.86\n",
      "2025-03-14T12:48:23.285651+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:48:23.286376+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(4/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 173.09it/s]\n",
      "(5/29): Calibrating: 100%|██████████| 512/512 [00:32<00:00, 15.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:48:58.836995+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.4.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:49:00.123529+0800 | compress | METRIC - time 1.28s\n",
      "2025-03-14T12:49:00.125417+0800 | compress | METRIC - error 280.60\n",
      "2025-03-14T12:49:00.126918+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:49:00.127655+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T12:49:00.128990+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.4.self_attn.k_proj using 512 samples\n",
      "2025-03-14T12:49:01.234345+0800 | compress | METRIC - time 1.10s\n",
      "2025-03-14T12:49:01.236172+0800 | compress | METRIC - error 82.86\n",
      "2025-03-14T12:49:01.237883+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:49:01.238656+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:49:01.240112+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.4.self_attn.v_proj using 512 samples\n",
      "2025-03-14T12:49:02.363235+0800 | compress | METRIC - time 1.12s\n",
      "2025-03-14T12:49:02.364997+0800 | compress | METRIC - error 6.37\n",
      "2025-03-14T12:49:02.366681+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:49:02.367387+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:49:02.368702+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.4.self_attn.o_proj using 512 samples\n",
      "2025-03-14T12:49:03.545648+0800 | compress | METRIC - time 1.18s\n",
      "2025-03-14T12:49:03.547546+0800 | compress | METRIC - error 1.47\n",
      "2025-03-14T12:49:03.549002+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:49:03.549644+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T12:49:03.550966+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.4.mlp.gate_proj using 512 samples\n",
      "2025-03-14T12:49:04.949556+0800 | compress | METRIC - time 1.40s\n",
      "2025-03-14T12:49:04.951109+0800 | compress | METRIC - error 6977.56\n",
      "2025-03-14T12:49:04.951805+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:49:04.952143+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:49:04.952747+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.4.mlp.up_proj using 512 samples\n",
      "2025-03-14T12:49:06.343967+0800 | compress | METRIC - time 1.39s\n",
      "2025-03-14T12:49:06.345616+0800 | compress | METRIC - error 833.35\n",
      "2025-03-14T12:49:06.346490+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:49:06.347086+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:49:06.348451+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.4.mlp.down_proj using 512 samples\n",
      "2025-03-14T12:49:13.686519+0800 | compress | METRIC - time 7.34s\n",
      "2025-03-14T12:49:13.691842+0800 | compress | METRIC - error 12.74\n",
      "2025-03-14T12:49:13.693593+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:49:13.694349+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(5/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 150.56it/s]\n",
      "(6/29): Calibrating: 100%|██████████| 512/512 [00:32<00:00, 15.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:49:49.435791+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.5.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:49:50.699347+0800 | compress | METRIC - time 1.26s\n",
      "2025-03-14T12:49:50.700792+0800 | compress | METRIC - error 291.09\n",
      "2025-03-14T12:49:50.701661+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:49:50.702369+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T12:49:50.704002+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.5.self_attn.k_proj using 512 samples\n",
      "2025-03-14T12:49:51.801343+0800 | compress | METRIC - time 1.10s\n",
      "2025-03-14T12:49:51.803142+0800 | compress | METRIC - error 69.55\n",
      "2025-03-14T12:49:51.804772+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:49:51.805492+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:49:51.806943+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.5.self_attn.v_proj using 512 samples\n",
      "2025-03-14T12:49:53.036834+0800 | compress | METRIC - time 1.23s\n",
      "2025-03-14T12:49:53.038688+0800 | compress | METRIC - error 10.31\n",
      "2025-03-14T12:49:53.040074+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:49:53.040810+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:49:53.041612+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.5.self_attn.o_proj using 512 samples\n",
      "2025-03-14T12:49:54.491808+0800 | compress | METRIC - time 1.45s\n",
      "2025-03-14T12:49:54.493832+0800 | compress | METRIC - error 1.73\n",
      "2025-03-14T12:49:54.495270+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:49:54.495935+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T12:49:54.497278+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.5.mlp.gate_proj using 512 samples\n",
      "2025-03-14T12:49:56.025516+0800 | compress | METRIC - time 1.53s\n",
      "2025-03-14T12:49:56.027460+0800 | compress | METRIC - error 12056.98\n",
      "2025-03-14T12:49:56.029108+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:49:56.029886+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:49:56.031273+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.5.mlp.up_proj using 512 samples\n",
      "2025-03-14T12:49:57.427958+0800 | compress | METRIC - time 1.40s\n",
      "2025-03-14T12:49:57.429763+0800 | compress | METRIC - error 1454.19\n",
      "2025-03-14T12:49:57.431391+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:49:57.432065+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:49:57.433380+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.5.mlp.down_proj using 512 samples\n",
      "2025-03-14T12:50:04.784798+0800 | compress | METRIC - time 7.35s\n",
      "2025-03-14T12:50:04.788666+0800 | compress | METRIC - error 9.07\n",
      "2025-03-14T12:50:04.789234+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:50:04.789543+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(6/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 132.65it/s]\n",
      "(7/29): Calibrating: 100%|██████████| 512/512 [00:32<00:00, 15.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:50:40.850819+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.6.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:50:42.149291+0800 | compress | METRIC - time 1.30s\n",
      "2025-03-14T12:50:42.151262+0800 | compress | METRIC - error 260.44\n",
      "2025-03-14T12:50:42.152901+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:50:42.153633+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T12:50:42.155074+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.6.self_attn.k_proj using 512 samples\n",
      "2025-03-14T12:50:43.277830+0800 | compress | METRIC - time 1.12s\n",
      "2025-03-14T12:50:43.279527+0800 | compress | METRIC - error 50.04\n",
      "2025-03-14T12:50:43.281088+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:50:43.281815+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:50:43.283115+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.6.self_attn.v_proj using 512 samples\n",
      "2025-03-14T12:50:44.423722+0800 | compress | METRIC - time 1.14s\n",
      "2025-03-14T12:50:44.425741+0800 | compress | METRIC - error 8.99\n",
      "2025-03-14T12:50:44.426715+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:50:44.428023+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:50:44.428778+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.6.self_attn.o_proj using 512 samples\n",
      "2025-03-14T12:50:45.644744+0800 | compress | METRIC - time 1.22s\n",
      "2025-03-14T12:50:45.646746+0800 | compress | METRIC - error 2.25\n",
      "2025-03-14T12:50:45.647733+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:50:45.648475+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T12:50:45.650125+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.6.mlp.gate_proj using 512 samples\n",
      "2025-03-14T12:50:47.073541+0800 | compress | METRIC - time 1.42s\n",
      "2025-03-14T12:50:47.075457+0800 | compress | METRIC - error 6731.52\n",
      "2025-03-14T12:50:47.076885+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:50:47.077449+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:50:47.078581+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.6.mlp.up_proj using 512 samples\n",
      "2025-03-14T12:50:48.492174+0800 | compress | METRIC - time 1.41s\n",
      "2025-03-14T12:50:48.494063+0800 | compress | METRIC - error 280.19\n",
      "2025-03-14T12:50:48.495613+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:50:48.496243+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:50:48.497523+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.6.mlp.down_proj using 512 samples\n",
      "2025-03-14T12:50:55.872368+0800 | compress | METRIC - time 7.37s\n",
      "2025-03-14T12:50:55.876342+0800 | compress | METRIC - error 18.83\n",
      "2025-03-14T12:50:55.878010+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:50:55.878767+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(7/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 134.12it/s]\n",
      "(8/29): Calibrating: 100%|██████████| 512/512 [00:32<00:00, 15.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:51:32.002550+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.7.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:51:33.488839+0800 | compress | METRIC - time 1.49s\n",
      "2025-03-14T12:51:33.490421+0800 | compress | METRIC - error 405.46\n",
      "2025-03-14T12:51:33.491958+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:51:33.492635+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T12:51:33.493945+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.7.self_attn.k_proj using 512 samples\n",
      "2025-03-14T12:51:34.812181+0800 | compress | METRIC - time 1.32s\n",
      "2025-03-14T12:51:34.814337+0800 | compress | METRIC - error 75.62\n",
      "2025-03-14T12:51:34.815389+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:51:34.816887+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:51:34.818087+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.7.self_attn.v_proj using 512 samples\n",
      "2025-03-14T12:51:36.150376+0800 | compress | METRIC - time 1.33s\n",
      "2025-03-14T12:51:36.152393+0800 | compress | METRIC - error 11.55\n",
      "2025-03-14T12:51:36.153422+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:51:36.154173+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:51:36.155830+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.7.self_attn.o_proj using 512 samples\n",
      "2025-03-14T12:51:37.473041+0800 | compress | METRIC - time 1.32s\n",
      "2025-03-14T12:51:37.474757+0800 | compress | METRIC - error 4.85\n",
      "2025-03-14T12:51:37.476410+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:51:37.477073+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T12:51:37.478003+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.7.mlp.gate_proj using 512 samples\n",
      "2025-03-14T12:51:38.887735+0800 | compress | METRIC - time 1.41s\n",
      "2025-03-14T12:51:38.889023+0800 | compress | METRIC - error 1141.71\n",
      "2025-03-14T12:51:38.890036+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:51:38.890713+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:51:38.892425+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.7.mlp.up_proj using 512 samples\n",
      "2025-03-14T12:51:40.281758+0800 | compress | METRIC - time 1.39s\n",
      "2025-03-14T12:51:40.283591+0800 | compress | METRIC - error 278.12\n",
      "2025-03-14T12:51:40.285183+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:51:40.285907+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:51:40.287326+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.7.mlp.down_proj using 512 samples\n",
      "2025-03-14T12:51:47.590233+0800 | compress | METRIC - time 7.30s\n",
      "2025-03-14T12:51:47.594563+0800 | compress | METRIC - error 29.21\n",
      "2025-03-14T12:51:47.596087+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:51:47.596768+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(8/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 137.64it/s]\n",
      "(9/29): Calibrating: 100%|██████████| 512/512 [00:32<00:00, 15.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:52:23.639308+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.8.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:52:24.926423+0800 | compress | METRIC - time 1.28s\n",
      "2025-03-14T12:52:24.928193+0800 | compress | METRIC - error 524.36\n",
      "2025-03-14T12:52:24.929858+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:52:24.930545+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T12:52:24.931821+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.8.self_attn.k_proj using 512 samples\n",
      "2025-03-14T12:52:26.058254+0800 | compress | METRIC - time 1.13s\n",
      "2025-03-14T12:52:26.060089+0800 | compress | METRIC - error 100.43\n",
      "2025-03-14T12:52:26.061408+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:52:26.062029+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:52:26.063173+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.8.self_attn.v_proj using 512 samples\n",
      "2025-03-14T12:52:27.207722+0800 | compress | METRIC - time 1.14s\n",
      "2025-03-14T12:52:27.209873+0800 | compress | METRIC - error 12.05\n",
      "2025-03-14T12:52:27.211265+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:52:27.211746+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:52:27.212612+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.8.self_attn.o_proj using 512 samples\n",
      "2025-03-14T12:52:28.408418+0800 | compress | METRIC - time 1.20s\n",
      "2025-03-14T12:52:28.411926+0800 | compress | METRIC - error 4.56\n",
      "2025-03-14T12:52:28.413232+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:52:28.414161+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T12:52:28.415592+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.8.mlp.gate_proj using 512 samples\n",
      "2025-03-14T12:52:29.814479+0800 | compress | METRIC - time 1.40s\n",
      "2025-03-14T12:52:29.816168+0800 | compress | METRIC - error 1291.90\n",
      "2025-03-14T12:52:29.817002+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:52:29.817589+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:52:29.818997+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.8.mlp.up_proj using 512 samples\n",
      "2025-03-14T12:52:31.223423+0800 | compress | METRIC - time 1.40s\n",
      "2025-03-14T12:52:31.225487+0800 | compress | METRIC - error 291.54\n",
      "2025-03-14T12:52:31.227060+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:52:31.227776+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:52:31.229110+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.8.mlp.down_proj using 512 samples\n",
      "2025-03-14T12:52:39.077945+0800 | compress | METRIC - time 7.85s\n",
      "2025-03-14T12:52:39.085224+0800 | compress | METRIC - error 30.31\n",
      "2025-03-14T12:52:39.086957+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:52:39.087768+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(9/29): Propagating: 100%|██████████| 512/512 [00:04<00:00, 117.53it/s]\n",
      "(10/29): Calibrating: 100%|██████████| 512/512 [00:33<00:00, 15.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:53:16.652523+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.9.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:53:17.927948+0800 | compress | METRIC - time 1.27s\n",
      "2025-03-14T12:53:17.930225+0800 | compress | METRIC - error 619.90\n",
      "2025-03-14T12:53:17.932463+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:53:17.933710+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T12:53:17.935029+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.9.self_attn.k_proj using 512 samples\n",
      "2025-03-14T12:53:19.271385+0800 | compress | METRIC - time 1.34s\n",
      "2025-03-14T12:53:19.273198+0800 | compress | METRIC - error 106.11\n",
      "2025-03-14T12:53:19.274108+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:53:19.274727+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:53:19.275898+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.9.self_attn.v_proj using 512 samples\n",
      "2025-03-14T12:53:20.545418+0800 | compress | METRIC - time 1.27s\n",
      "2025-03-14T12:53:20.547269+0800 | compress | METRIC - error 15.46\n",
      "2025-03-14T12:53:20.548930+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:53:20.549706+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:53:20.550652+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.9.self_attn.o_proj using 512 samples\n",
      "2025-03-14T12:53:21.749339+0800 | compress | METRIC - time 1.20s\n",
      "2025-03-14T12:53:21.751216+0800 | compress | METRIC - error 9.21\n",
      "2025-03-14T12:53:21.752142+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:53:21.752884+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T12:53:21.754696+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.9.mlp.gate_proj using 512 samples\n",
      "2025-03-14T12:53:23.177504+0800 | compress | METRIC - time 1.42s\n",
      "2025-03-14T12:53:23.179294+0800 | compress | METRIC - error 8546.99\n",
      "2025-03-14T12:53:23.180974+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:53:23.181709+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:53:23.183165+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.9.mlp.up_proj using 512 samples\n",
      "2025-03-14T12:53:24.584050+0800 | compress | METRIC - time 1.40s\n",
      "2025-03-14T12:53:24.587228+0800 | compress | METRIC - error 460.70\n",
      "2025-03-14T12:53:24.588807+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:53:24.589528+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:53:24.590982+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.9.mlp.down_proj using 512 samples\n",
      "2025-03-14T12:53:31.916279+0800 | compress | METRIC - time 7.32s\n",
      "2025-03-14T12:53:31.920604+0800 | compress | METRIC - error 26.37\n",
      "2025-03-14T12:53:31.921660+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:53:31.922474+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(10/29): Propagating: 100%|██████████| 512/512 [00:04<00:00, 126.36it/s]\n",
      "(11/29): Calibrating: 100%|██████████| 512/512 [00:33<00:00, 15.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:54:09.261815+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.10.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:54:10.796087+0800 | compress | METRIC - time 1.53s\n",
      "2025-03-14T12:54:10.798391+0800 | compress | METRIC - error 409.10\n",
      "2025-03-14T12:54:10.799821+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:54:10.800437+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T12:54:10.801571+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.10.self_attn.k_proj using 512 samples\n",
      "2025-03-14T12:54:12.086619+0800 | compress | METRIC - time 1.28s\n",
      "2025-03-14T12:54:12.088915+0800 | compress | METRIC - error 73.19\n",
      "2025-03-14T12:54:12.090624+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:54:12.091426+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:54:12.093069+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.10.self_attn.v_proj using 512 samples\n",
      "2025-03-14T12:54:13.232066+0800 | compress | METRIC - time 1.14s\n",
      "2025-03-14T12:54:13.234218+0800 | compress | METRIC - error 9.20\n",
      "2025-03-14T12:54:13.235999+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:54:13.236904+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:54:13.237775+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.10.self_attn.o_proj using 512 samples\n",
      "2025-03-14T12:54:14.695937+0800 | compress | METRIC - time 1.46s\n",
      "2025-03-14T12:54:14.701029+0800 | compress | METRIC - error 5.41\n",
      "2025-03-14T12:54:14.702198+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:54:14.703050+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T12:54:14.705001+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.10.mlp.gate_proj using 512 samples\n",
      "2025-03-14T12:54:16.364768+0800 | compress | METRIC - time 1.66s\n",
      "2025-03-14T12:54:16.366877+0800 | compress | METRIC - error 748.20\n",
      "2025-03-14T12:54:16.367897+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:54:16.368644+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:54:16.370419+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.10.mlp.up_proj using 512 samples\n",
      "2025-03-14T12:54:17.890628+0800 | compress | METRIC - time 1.52s\n",
      "2025-03-14T12:54:17.892558+0800 | compress | METRIC - error 302.37\n",
      "2025-03-14T12:54:17.893539+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:54:17.894144+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:54:17.895527+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.10.mlp.down_proj using 512 samples\n",
      "2025-03-14T12:54:25.541559+0800 | compress | METRIC - time 7.65s\n",
      "2025-03-14T12:54:25.548362+0800 | compress | METRIC - error 26.39\n",
      "2025-03-14T12:54:25.550700+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:54:25.551688+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(11/29): Propagating: 100%|██████████| 512/512 [00:04<00:00, 114.76it/s]\n",
      "(12/29): Calibrating: 100%|██████████| 512/512 [00:33<00:00, 15.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:55:03.329740+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.11.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:55:04.632207+0800 | compress | METRIC - time 1.30s\n",
      "2025-03-14T12:55:04.634192+0800 | compress | METRIC - error 426.52\n",
      "2025-03-14T12:55:04.635837+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:55:04.636479+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T12:55:04.637595+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.11.self_attn.k_proj using 512 samples\n",
      "2025-03-14T12:55:05.748076+0800 | compress | METRIC - time 1.11s\n",
      "2025-03-14T12:55:05.749932+0800 | compress | METRIC - error 90.15\n",
      "2025-03-14T12:55:05.751396+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:55:05.751996+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:55:05.753382+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.11.self_attn.v_proj using 512 samples\n",
      "2025-03-14T12:55:06.866980+0800 | compress | METRIC - time 1.11s\n",
      "2025-03-14T12:55:06.868919+0800 | compress | METRIC - error 10.64\n",
      "2025-03-14T12:55:06.869854+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:55:06.870466+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:55:06.871933+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.11.self_attn.o_proj using 512 samples\n",
      "2025-03-14T12:55:08.064678+0800 | compress | METRIC - time 1.19s\n",
      "2025-03-14T12:55:08.068037+0800 | compress | METRIC - error 5.43\n",
      "2025-03-14T12:55:08.069635+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:55:08.070263+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T12:55:08.071450+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.11.mlp.gate_proj using 512 samples\n",
      "2025-03-14T12:55:09.487991+0800 | compress | METRIC - time 1.42s\n",
      "2025-03-14T12:55:09.489220+0800 | compress | METRIC - error 483.58\n",
      "2025-03-14T12:55:09.490919+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:55:09.491628+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:55:09.493075+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.11.mlp.up_proj using 512 samples\n",
      "2025-03-14T12:55:10.861773+0800 | compress | METRIC - time 1.37s\n",
      "2025-03-14T12:55:10.863656+0800 | compress | METRIC - error 294.00\n",
      "2025-03-14T12:55:10.865058+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:55:10.865621+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:55:10.866265+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.11.mlp.down_proj using 512 samples\n",
      "2025-03-14T12:55:18.074761+0800 | compress | METRIC - time 7.21s\n",
      "2025-03-14T12:55:18.078855+0800 | compress | METRIC - error 21.09\n",
      "2025-03-14T12:55:18.080519+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:55:18.081195+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(12/29): Propagating: 100%|██████████| 512/512 [00:04<00:00, 126.55it/s]\n",
      "(13/29): Calibrating: 100%|██████████| 512/512 [00:33<00:00, 15.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:55:55.161827+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.12.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:55:56.444964+0800 | compress | METRIC - time 1.28s\n",
      "2025-03-14T12:55:56.446977+0800 | compress | METRIC - error 460.08\n",
      "2025-03-14T12:55:56.448045+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:55:56.448885+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T12:55:56.450843+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.12.self_attn.k_proj using 512 samples\n",
      "2025-03-14T12:55:57.554560+0800 | compress | METRIC - time 1.10s\n",
      "2025-03-14T12:55:57.556250+0800 | compress | METRIC - error 99.49\n",
      "2025-03-14T12:55:57.557931+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:55:57.558722+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:55:57.560146+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.12.self_attn.v_proj using 512 samples\n",
      "2025-03-14T12:55:58.684403+0800 | compress | METRIC - time 1.12s\n",
      "2025-03-14T12:55:58.685719+0800 | compress | METRIC - error 13.85\n",
      "2025-03-14T12:55:58.686740+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:55:58.687499+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:55:58.689302+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.12.self_attn.o_proj using 512 samples\n",
      "2025-03-14T12:55:59.881803+0800 | compress | METRIC - time 1.19s\n",
      "2025-03-14T12:55:59.883350+0800 | compress | METRIC - error 4.84\n",
      "2025-03-14T12:55:59.884225+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:55:59.884669+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T12:55:59.885455+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.12.mlp.gate_proj using 512 samples\n",
      "2025-03-14T12:56:01.387381+0800 | compress | METRIC - time 1.50s\n",
      "2025-03-14T12:56:01.389175+0800 | compress | METRIC - error 529.77\n",
      "2025-03-14T12:56:01.390105+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:56:01.391434+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:56:01.392459+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.12.mlp.up_proj using 512 samples\n",
      "2025-03-14T12:56:02.910230+0800 | compress | METRIC - time 1.52s\n",
      "2025-03-14T12:56:02.912048+0800 | compress | METRIC - error 314.28\n",
      "2025-03-14T12:56:02.913678+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:56:02.914407+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:56:02.915840+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.12.mlp.down_proj using 512 samples\n",
      "2025-03-14T12:56:10.305283+0800 | compress | METRIC - time 7.39s\n",
      "2025-03-14T12:56:10.310931+0800 | compress | METRIC - error 29.17\n",
      "2025-03-14T12:56:10.312341+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:56:10.314040+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(13/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 128.76it/s]\n",
      "(14/29): Calibrating: 100%|██████████| 512/512 [00:32<00:00, 15.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:56:47.146367+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.13.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:56:48.425684+0800 | compress | METRIC - time 1.28s\n",
      "2025-03-14T12:56:48.427174+0800 | compress | METRIC - error 463.04\n",
      "2025-03-14T12:56:48.428101+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:56:48.428523+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T12:56:48.429279+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.13.self_attn.k_proj using 512 samples\n",
      "2025-03-14T12:56:49.525719+0800 | compress | METRIC - time 1.10s\n",
      "2025-03-14T12:56:49.527385+0800 | compress | METRIC - error 106.60\n",
      "2025-03-14T12:56:49.528860+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:56:49.529508+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:56:49.530796+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.13.self_attn.v_proj using 512 samples\n",
      "2025-03-14T12:56:50.620787+0800 | compress | METRIC - time 1.09s\n",
      "2025-03-14T12:56:50.622536+0800 | compress | METRIC - error 16.14\n",
      "2025-03-14T12:56:50.623598+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:56:50.624386+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:56:50.625821+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.13.self_attn.o_proj using 512 samples\n",
      "2025-03-14T12:56:51.800938+0800 | compress | METRIC - time 1.17s\n",
      "2025-03-14T12:56:51.802604+0800 | compress | METRIC - error 9.88\n",
      "2025-03-14T12:56:51.804271+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:56:51.805012+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T12:56:51.806264+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.13.mlp.gate_proj using 512 samples\n",
      "2025-03-14T12:56:53.309706+0800 | compress | METRIC - time 1.50s\n",
      "2025-03-14T12:56:53.311348+0800 | compress | METRIC - error 671.13\n",
      "2025-03-14T12:56:53.312331+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:56:53.313044+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:56:53.314821+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.13.mlp.up_proj using 512 samples\n",
      "2025-03-14T12:56:54.791493+0800 | compress | METRIC - time 1.48s\n",
      "2025-03-14T12:56:54.793219+0800 | compress | METRIC - error 327.94\n",
      "2025-03-14T12:56:54.794722+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:56:54.795373+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:56:54.796690+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.13.mlp.down_proj using 512 samples\n",
      "2025-03-14T12:57:02.312372+0800 | compress | METRIC - time 7.52s\n",
      "2025-03-14T12:57:02.317328+0800 | compress | METRIC - error 26.64\n",
      "2025-03-14T12:57:02.318798+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:57:02.319909+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(14/29): Propagating: 100%|██████████| 512/512 [00:04<00:00, 122.37it/s]\n",
      "(15/29): Calibrating: 100%|██████████| 512/512 [00:32<00:00, 15.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:57:38.984491+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.14.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:57:40.356958+0800 | compress | METRIC - time 1.37s\n",
      "2025-03-14T12:57:40.358945+0800 | compress | METRIC - error 673.45\n",
      "2025-03-14T12:57:40.360447+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:57:40.361716+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T12:57:40.364597+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.14.self_attn.k_proj using 512 samples\n",
      "2025-03-14T12:57:41.483661+0800 | compress | METRIC - time 1.12s\n",
      "2025-03-14T12:57:41.485565+0800 | compress | METRIC - error 174.74\n",
      "2025-03-14T12:57:41.486732+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:57:41.487761+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:57:41.490719+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.14.self_attn.v_proj using 512 samples\n",
      "2025-03-14T12:57:42.610163+0800 | compress | METRIC - time 1.12s\n",
      "2025-03-14T12:57:42.612140+0800 | compress | METRIC - error 27.16\n",
      "2025-03-14T12:57:42.613427+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:57:42.614529+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:57:42.617212+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.14.self_attn.o_proj using 512 samples\n",
      "2025-03-14T12:57:43.822362+0800 | compress | METRIC - time 1.20s\n",
      "2025-03-14T12:57:43.825225+0800 | compress | METRIC - error 8.21\n",
      "2025-03-14T12:57:43.826604+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:57:43.827607+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T12:57:43.828579+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.14.mlp.gate_proj using 512 samples\n",
      "2025-03-14T12:57:45.378137+0800 | compress | METRIC - time 1.55s\n",
      "2025-03-14T12:57:45.380302+0800 | compress | METRIC - error 600.73\n",
      "2025-03-14T12:57:45.381553+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:57:45.383203+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:57:45.384362+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.14.mlp.up_proj using 512 samples\n",
      "2025-03-14T12:57:46.934638+0800 | compress | METRIC - time 1.55s\n",
      "2025-03-14T12:57:46.936572+0800 | compress | METRIC - error 352.91\n",
      "2025-03-14T12:57:46.937905+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:57:46.938992+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:57:46.940817+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.14.mlp.down_proj using 512 samples\n",
      "2025-03-14T12:57:54.403467+0800 | compress | METRIC - time 7.46s\n",
      "2025-03-14T12:57:54.407501+0800 | compress | METRIC - error 32.79\n",
      "2025-03-14T12:57:54.409359+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:57:54.410116+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(15/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 136.83it/s]\n",
      "(16/29): Calibrating: 100%|██████████| 512/512 [00:32<00:00, 15.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:58:30.872203+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.15.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:58:32.166413+0800 | compress | METRIC - time 1.29s\n",
      "2025-03-14T12:58:32.168788+0800 | compress | METRIC - error 472.63\n",
      "2025-03-14T12:58:32.170316+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:58:32.170946+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T12:58:32.172058+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.15.self_attn.k_proj using 512 samples\n",
      "2025-03-14T12:58:33.270724+0800 | compress | METRIC - time 1.10s\n",
      "2025-03-14T12:58:33.272538+0800 | compress | METRIC - error 130.28\n",
      "2025-03-14T12:58:33.273505+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:58:33.274310+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:58:33.276139+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.15.self_attn.v_proj using 512 samples\n",
      "2025-03-14T12:58:34.388858+0800 | compress | METRIC - time 1.11s\n",
      "2025-03-14T12:58:34.390725+0800 | compress | METRIC - error 19.92\n",
      "2025-03-14T12:58:34.391698+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:58:34.392456+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:58:34.394208+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.15.self_attn.o_proj using 512 samples\n",
      "2025-03-14T12:58:35.587442+0800 | compress | METRIC - time 1.19s\n",
      "2025-03-14T12:58:35.589161+0800 | compress | METRIC - error 5.78\n",
      "2025-03-14T12:58:35.590135+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:58:35.590857+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T12:58:35.592562+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.15.mlp.gate_proj using 512 samples\n",
      "2025-03-14T12:58:37.032496+0800 | compress | METRIC - time 1.44s\n",
      "2025-03-14T12:58:37.034549+0800 | compress | METRIC - error 537.55\n",
      "2025-03-14T12:58:37.035573+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:58:37.036350+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:58:37.037827+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.15.mlp.up_proj using 512 samples\n",
      "2025-03-14T12:58:38.519007+0800 | compress | METRIC - time 1.48s\n",
      "2025-03-14T12:58:38.520675+0800 | compress | METRIC - error 374.40\n",
      "2025-03-14T12:58:38.521873+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:58:38.523132+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:58:38.525500+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.15.mlp.down_proj using 512 samples\n",
      "2025-03-14T12:58:46.013328+0800 | compress | METRIC - time 7.49s\n",
      "2025-03-14T12:58:46.017599+0800 | compress | METRIC - error 26.69\n",
      "2025-03-14T12:58:46.019215+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:58:46.019871+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(16/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 147.88it/s]\n",
      "(17/29): Calibrating: 100%|██████████| 512/512 [00:32<00:00, 15.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:59:22.043519+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.16.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T12:59:23.560618+0800 | compress | METRIC - time 1.52s\n",
      "2025-03-14T12:59:23.562810+0800 | compress | METRIC - error 603.14\n",
      "2025-03-14T12:59:23.564433+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:59:23.565158+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T12:59:23.566718+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.16.self_attn.k_proj using 512 samples\n",
      "2025-03-14T12:59:24.892854+0800 | compress | METRIC - time 1.33s\n",
      "2025-03-14T12:59:24.894893+0800 | compress | METRIC - error 207.77\n",
      "2025-03-14T12:59:24.896371+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:59:24.897083+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:59:24.898519+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.16.self_attn.v_proj using 512 samples\n",
      "2025-03-14T12:59:26.115570+0800 | compress | METRIC - time 1.22s\n",
      "2025-03-14T12:59:26.117377+0800 | compress | METRIC - error 16.54\n",
      "2025-03-14T12:59:26.119007+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:59:26.119681+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T12:59:26.121000+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.16.self_attn.o_proj using 512 samples\n",
      "2025-03-14T12:59:27.305618+0800 | compress | METRIC - time 1.18s\n",
      "2025-03-14T12:59:27.308379+0800 | compress | METRIC - error 10.75\n",
      "2025-03-14T12:59:27.309523+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:59:27.310286+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T12:59:27.312039+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.16.mlp.gate_proj using 512 samples\n",
      "2025-03-14T12:59:28.822275+0800 | compress | METRIC - time 1.51s\n",
      "2025-03-14T12:59:28.824398+0800 | compress | METRIC - error 485.44\n",
      "2025-03-14T12:59:28.825439+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:59:28.826216+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:59:28.828236+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.16.mlp.up_proj using 512 samples\n",
      "2025-03-14T12:59:30.361396+0800 | compress | METRIC - time 1.53s\n",
      "2025-03-14T12:59:30.363111+0800 | compress | METRIC - error 311.23\n",
      "2025-03-14T12:59:30.364837+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:59:30.365462+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T12:59:30.366624+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.16.mlp.down_proj using 512 samples\n",
      "2025-03-14T12:59:37.760181+0800 | compress | METRIC - time 7.39s\n",
      "2025-03-14T12:59:37.764349+0800 | compress | METRIC - error 26.34\n",
      "2025-03-14T12:59:37.766002+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T12:59:37.766752+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(17/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 154.29it/s]\n",
      "(18/29): Calibrating: 100%|██████████| 512/512 [00:32<00:00, 15.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T13:00:13.605574+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.17.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T13:00:14.868746+0800 | compress | METRIC - time 1.26s\n",
      "2025-03-14T13:00:14.870576+0800 | compress | METRIC - error 548.60\n",
      "2025-03-14T13:00:14.872213+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:00:14.872951+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T13:00:14.874376+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.17.self_attn.k_proj using 512 samples\n",
      "2025-03-14T13:00:15.958799+0800 | compress | METRIC - time 1.08s\n",
      "2025-03-14T13:00:15.960698+0800 | compress | METRIC - error 144.49\n",
      "2025-03-14T13:00:15.962388+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:00:15.963155+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T13:00:15.964602+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.17.self_attn.v_proj using 512 samples\n",
      "2025-03-14T13:00:17.060074+0800 | compress | METRIC - time 1.09s\n",
      "2025-03-14T13:00:17.062215+0800 | compress | METRIC - error 19.93\n",
      "2025-03-14T13:00:17.063945+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:00:17.064916+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T13:00:17.066600+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.17.self_attn.o_proj using 512 samples\n",
      "2025-03-14T13:00:18.456403+0800 | compress | METRIC - time 1.39s\n",
      "2025-03-14T13:00:18.458254+0800 | compress | METRIC - error 9.71\n",
      "2025-03-14T13:00:18.459891+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:00:18.460614+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T13:00:18.462112+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.17.mlp.gate_proj using 512 samples\n",
      "2025-03-14T13:00:19.942271+0800 | compress | METRIC - time 1.48s\n",
      "2025-03-14T13:00:19.944022+0800 | compress | METRIC - error 598.81\n",
      "2025-03-14T13:00:19.945240+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:00:19.945901+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T13:00:19.947363+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.17.mlp.up_proj using 512 samples\n",
      "2025-03-14T13:00:21.428721+0800 | compress | METRIC - time 1.48s\n",
      "2025-03-14T13:00:21.430515+0800 | compress | METRIC - error 367.81\n",
      "2025-03-14T13:00:21.431561+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:00:21.432266+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T13:00:21.433691+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.17.mlp.down_proj using 512 samples\n",
      "2025-03-14T13:00:28.892398+0800 | compress | METRIC - time 7.46s\n",
      "2025-03-14T13:00:28.898918+0800 | compress | METRIC - error 39.02\n",
      "2025-03-14T13:00:28.900205+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:00:28.901149+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(18/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 138.31it/s]\n",
      "(21/29): Calibrating: 100%|██████████| 512/512 [00:32<00:00, 15.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T13:02:47.643947+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.20.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T13:02:49.204509+0800 | compress | METRIC - time 1.56s\n",
      "2025-03-14T13:02:49.206137+0800 | compress | METRIC - error 469.20\n",
      "2025-03-14T13:02:49.207280+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:02:49.208734+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T13:02:49.209882+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.20.self_attn.k_proj using 512 samples\n",
      "2025-03-14T13:02:50.525348+0800 | compress | METRIC - time 1.31s\n",
      "2025-03-14T13:02:50.526991+0800 | compress | METRIC - error 151.65\n",
      "2025-03-14T13:02:50.528633+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:02:50.529368+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T13:02:50.530877+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.20.self_attn.v_proj using 512 samples\n",
      "2025-03-14T13:02:51.863937+0800 | compress | METRIC - time 1.33s\n",
      "2025-03-14T13:02:51.866095+0800 | compress | METRIC - error 34.55\n",
      "2025-03-14T13:02:51.867686+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:02:51.868409+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T13:02:51.869883+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.20.self_attn.o_proj using 512 samples\n",
      "2025-03-14T13:02:53.285371+0800 | compress | METRIC - time 1.41s\n",
      "2025-03-14T13:02:53.287600+0800 | compress | METRIC - error 13.39\n",
      "2025-03-14T13:02:53.289394+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:02:53.290385+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T13:02:53.291695+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.20.mlp.gate_proj using 512 samples\n",
      "2025-03-14T13:02:54.856199+0800 | compress | METRIC - time 1.56s\n",
      "2025-03-14T13:02:54.857975+0800 | compress | METRIC - error 1407.41\n",
      "2025-03-14T13:02:54.859535+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:02:54.860184+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T13:02:54.861367+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.20.mlp.up_proj using 512 samples\n",
      "2025-03-14T13:02:56.387935+0800 | compress | METRIC - time 1.53s\n",
      "2025-03-14T13:02:56.389942+0800 | compress | METRIC - error 742.72\n",
      "2025-03-14T13:02:56.391703+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:02:56.393004+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T13:02:56.394781+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.20.mlp.down_proj using 512 samples\n",
      "2025-03-14T13:03:03.731480+0800 | compress | METRIC - time 7.34s\n",
      "2025-03-14T13:03:03.735420+0800 | compress | METRIC - error 136.91\n",
      "2025-03-14T13:03:03.737124+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:03:03.737976+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(21/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 131.68it/s]\n",
      "(22/29): Calibrating: 100%|██████████| 512/512 [00:32<00:00, 15.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T13:03:39.928712+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.21.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T13:03:41.429897+0800 | compress | METRIC - time 1.50s\n",
      "2025-03-14T13:03:41.431895+0800 | compress | METRIC - error 786.42\n",
      "2025-03-14T13:03:41.433107+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:03:41.434099+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T13:03:41.435560+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.21.self_attn.k_proj using 512 samples\n",
      "2025-03-14T13:03:42.750296+0800 | compress | METRIC - time 1.31s\n",
      "2025-03-14T13:03:42.752338+0800 | compress | METRIC - error 213.99\n",
      "2025-03-14T13:03:42.753516+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:03:42.754285+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T13:03:42.755718+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.21.self_attn.v_proj using 512 samples\n",
      "2025-03-14T13:03:44.095914+0800 | compress | METRIC - time 1.34s\n",
      "2025-03-14T13:03:44.098034+0800 | compress | METRIC - error 49.65\n",
      "2025-03-14T13:03:44.099761+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:03:44.101261+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T13:03:44.103010+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.21.self_attn.o_proj using 512 samples\n",
      "2025-03-14T13:03:45.525863+0800 | compress | METRIC - time 1.42s\n",
      "2025-03-14T13:03:45.527888+0800 | compress | METRIC - error 31.78\n",
      "2025-03-14T13:03:45.529710+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:03:45.530883+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T13:03:45.532584+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.21.mlp.gate_proj using 512 samples\n",
      "2025-03-14T13:03:47.296019+0800 | compress | METRIC - time 1.76s\n",
      "2025-03-14T13:03:47.298089+0800 | compress | METRIC - error 2253.62\n",
      "2025-03-14T13:03:47.299779+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:03:47.300878+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T13:03:47.302586+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.21.mlp.up_proj using 512 samples\n",
      "2025-03-14T13:03:49.068476+0800 | compress | METRIC - time 1.76s\n",
      "2025-03-14T13:03:49.070341+0800 | compress | METRIC - error 950.42\n",
      "2025-03-14T13:03:49.072287+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:03:49.073384+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T13:03:49.075370+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.21.mlp.down_proj using 512 samples\n",
      "2025-03-14T13:03:56.534415+0800 | compress | METRIC - time 7.46s\n",
      "2025-03-14T13:03:56.538551+0800 | compress | METRIC - error 186.16\n",
      "2025-03-14T13:03:56.540284+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:03:56.541046+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(22/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 140.55it/s]\n",
      "(23/29): Calibrating: 100%|██████████| 512/512 [00:32<00:00, 15.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T13:04:32.499137+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.22.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T13:04:33.788362+0800 | compress | METRIC - time 1.29s\n",
      "2025-03-14T13:04:33.790119+0800 | compress | METRIC - error 1017.86\n",
      "2025-03-14T13:04:33.791728+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:04:33.792400+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T13:04:33.793700+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.22.self_attn.k_proj using 512 samples\n",
      "2025-03-14T13:04:34.885620+0800 | compress | METRIC - time 1.09s\n",
      "2025-03-14T13:04:34.887330+0800 | compress | METRIC - error 272.80\n",
      "2025-03-14T13:04:34.888994+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:04:34.890002+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T13:04:34.891407+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.22.self_attn.v_proj using 512 samples\n",
      "2025-03-14T13:04:36.235004+0800 | compress | METRIC - time 1.34s\n",
      "2025-03-14T13:04:36.237246+0800 | compress | METRIC - error 121.29\n",
      "2025-03-14T13:04:36.238619+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:04:36.239811+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T13:04:36.240831+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.22.self_attn.o_proj using 512 samples\n",
      "2025-03-14T13:04:37.669853+0800 | compress | METRIC - time 1.43s\n",
      "2025-03-14T13:04:37.671820+0800 | compress | METRIC - error 18.96\n",
      "2025-03-14T13:04:37.673725+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:04:37.674541+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T13:04:37.675981+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.22.mlp.gate_proj using 512 samples\n",
      "2025-03-14T13:04:39.425957+0800 | compress | METRIC - time 1.75s\n",
      "2025-03-14T13:04:39.428212+0800 | compress | METRIC - error 3268.17\n",
      "2025-03-14T13:04:39.429581+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:04:39.430670+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T13:04:39.432488+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.22.mlp.up_proj using 512 samples\n",
      "2025-03-14T13:04:40.979461+0800 | compress | METRIC - time 1.55s\n",
      "2025-03-14T13:04:40.981121+0800 | compress | METRIC - error 1426.25\n",
      "2025-03-14T13:04:40.982842+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:04:40.983550+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T13:04:40.984981+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.22.mlp.down_proj using 512 samples\n",
      "2025-03-14T13:04:48.409398+0800 | compress | METRIC - time 7.42s\n",
      "2025-03-14T13:04:48.413251+0800 | compress | METRIC - error 321.66\n",
      "2025-03-14T13:04:48.414817+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:04:48.415531+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(23/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 146.31it/s]\n",
      "(24/29): Calibrating: 100%|██████████| 512/512 [00:32<00:00, 15.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T13:05:24.350160+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.23.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T13:05:25.649430+0800 | compress | METRIC - time 1.30s\n",
      "2025-03-14T13:05:25.651408+0800 | compress | METRIC - error 930.52\n",
      "2025-03-14T13:05:25.653553+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:05:25.654507+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T13:05:25.655903+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.23.self_attn.k_proj using 512 samples\n",
      "2025-03-14T13:05:26.969386+0800 | compress | METRIC - time 1.31s\n",
      "2025-03-14T13:05:26.971341+0800 | compress | METRIC - error 252.67\n",
      "2025-03-14T13:05:26.972558+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:05:26.974548+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T13:05:26.975973+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.23.self_attn.v_proj using 512 samples\n",
      "2025-03-14T13:05:28.321143+0800 | compress | METRIC - time 1.34s\n",
      "2025-03-14T13:05:28.323598+0800 | compress | METRIC - error 278.23\n",
      "2025-03-14T13:05:28.325206+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:05:28.326317+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T13:05:28.328227+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.23.self_attn.o_proj using 512 samples\n",
      "2025-03-14T13:05:29.737967+0800 | compress | METRIC - time 1.41s\n",
      "2025-03-14T13:05:29.739816+0800 | compress | METRIC - error 40.95\n",
      "2025-03-14T13:05:29.741061+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:05:29.742115+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T13:05:29.744299+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.23.mlp.gate_proj using 512 samples\n",
      "2025-03-14T13:05:31.343305+0800 | compress | METRIC - time 1.60s\n",
      "2025-03-14T13:05:31.345590+0800 | compress | METRIC - error 4032.72\n",
      "2025-03-14T13:05:31.347061+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:05:31.348278+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T13:05:31.349998+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.23.mlp.up_proj using 512 samples\n",
      "2025-03-14T13:05:32.864774+0800 | compress | METRIC - time 1.51s\n",
      "2025-03-14T13:05:32.865729+0800 | compress | METRIC - error 1614.94\n",
      "2025-03-14T13:05:32.866523+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:05:32.867066+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T13:05:32.867653+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.23.mlp.down_proj using 512 samples\n",
      "2025-03-14T13:05:40.173131+0800 | compress | METRIC - time 7.30s\n",
      "2025-03-14T13:05:40.176819+0800 | compress | METRIC - error 347.27\n",
      "2025-03-14T13:05:40.177740+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:05:40.178464+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(24/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 145.01it/s]\n",
      "(25/29): Calibrating: 100%|██████████| 512/512 [00:32<00:00, 15.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T13:06:16.202248+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.24.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T13:06:17.716970+0800 | compress | METRIC - time 1.51s\n",
      "2025-03-14T13:06:17.719207+0800 | compress | METRIC - error 744.78\n",
      "2025-03-14T13:06:17.720554+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:06:17.722532+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T13:06:17.723735+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.24.self_attn.k_proj using 512 samples\n",
      "2025-03-14T13:06:18.942618+0800 | compress | METRIC - time 1.22s\n",
      "2025-03-14T13:06:18.944396+0800 | compress | METRIC - error 166.20\n",
      "2025-03-14T13:06:18.945391+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:06:18.946022+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T13:06:18.947413+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.24.self_attn.v_proj using 512 samples\n",
      "2025-03-14T13:06:20.046020+0800 | compress | METRIC - time 1.10s\n",
      "2025-03-14T13:06:20.048353+0800 | compress | METRIC - error 270.00\n",
      "2025-03-14T13:06:20.049866+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:06:20.050596+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T13:06:20.052027+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.24.self_attn.o_proj using 512 samples\n",
      "2025-03-14T13:06:21.243709+0800 | compress | METRIC - time 1.19s\n",
      "2025-03-14T13:06:21.245403+0800 | compress | METRIC - error 29.90\n",
      "2025-03-14T13:06:21.246380+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:06:21.247711+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T13:06:21.249107+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.24.mlp.gate_proj using 512 samples\n",
      "2025-03-14T13:06:22.746754+0800 | compress | METRIC - time 1.50s\n",
      "2025-03-14T13:06:22.748226+0800 | compress | METRIC - error 3462.46\n",
      "2025-03-14T13:06:22.749510+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:06:22.751133+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T13:06:22.752379+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.24.mlp.up_proj using 512 samples\n",
      "2025-03-14T13:06:24.380452+0800 | compress | METRIC - time 1.63s\n",
      "2025-03-14T13:06:24.382469+0800 | compress | METRIC - error 1885.30\n",
      "2025-03-14T13:06:24.384350+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:06:24.385434+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T13:06:24.387367+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.24.mlp.down_proj using 512 samples\n",
      "2025-03-14T13:06:31.900841+0800 | compress | METRIC - time 7.51s\n",
      "2025-03-14T13:06:31.904875+0800 | compress | METRIC - error 486.67\n",
      "2025-03-14T13:06:31.906313+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:06:31.907344+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(25/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 153.98it/s]\n",
      "(26/29): Calibrating: 100%|██████████| 512/512 [00:32<00:00, 15.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T13:07:07.799468+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.25.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T13:07:09.088937+0800 | compress | METRIC - time 1.29s\n",
      "2025-03-14T13:07:09.090854+0800 | compress | METRIC - error 747.56\n",
      "2025-03-14T13:07:09.092524+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:07:09.093321+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T13:07:09.095267+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.25.self_attn.k_proj using 512 samples\n",
      "2025-03-14T13:07:10.196648+0800 | compress | METRIC - time 1.10s\n",
      "2025-03-14T13:07:10.199575+0800 | compress | METRIC - error 178.98\n",
      "2025-03-14T13:07:10.201057+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:07:10.201864+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T13:07:10.203838+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.25.self_attn.v_proj using 512 samples\n",
      "2025-03-14T13:07:11.316520+0800 | compress | METRIC - time 1.11s\n",
      "2025-03-14T13:07:11.318304+0800 | compress | METRIC - error 456.42\n",
      "2025-03-14T13:07:11.319901+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:07:11.320646+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T13:07:11.322122+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.25.self_attn.o_proj using 512 samples\n",
      "2025-03-14T13:07:12.542329+0800 | compress | METRIC - time 1.22s\n",
      "2025-03-14T13:07:12.544557+0800 | compress | METRIC - error 48.77\n",
      "2025-03-14T13:07:12.545706+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:07:12.546488+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T13:07:12.548384+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.25.mlp.gate_proj using 512 samples\n",
      "2025-03-14T13:07:14.088510+0800 | compress | METRIC - time 1.54s\n",
      "2025-03-14T13:07:14.090339+0800 | compress | METRIC - error 3500.62\n",
      "2025-03-14T13:07:14.091807+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:07:14.092507+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T13:07:14.093863+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.25.mlp.up_proj using 512 samples\n",
      "2025-03-14T13:07:15.638607+0800 | compress | METRIC - time 1.54s\n",
      "2025-03-14T13:07:15.640856+0800 | compress | METRIC - error 3156.15\n",
      "2025-03-14T13:07:15.642376+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:07:15.643533+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T13:07:15.645388+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.25.mlp.down_proj using 512 samples\n",
      "2025-03-14T13:07:23.202573+0800 | compress | METRIC - time 7.56s\n",
      "2025-03-14T13:07:23.206259+0800 | compress | METRIC - error 698.15\n",
      "2025-03-14T13:07:23.206847+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:07:23.207294+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(26/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 157.71it/s]\n",
      "(27/29): Calibrating: 100%|██████████| 512/512 [00:32<00:00, 15.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T13:07:58.938736+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.26.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T13:08:00.212708+0800 | compress | METRIC - time 1.27s\n",
      "2025-03-14T13:08:00.214501+0800 | compress | METRIC - error 1150.32\n",
      "2025-03-14T13:08:00.215669+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:08:00.216683+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T13:08:00.218443+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.26.self_attn.k_proj using 512 samples\n",
      "2025-03-14T13:08:01.319475+0800 | compress | METRIC - time 1.10s\n",
      "2025-03-14T13:08:01.321187+0800 | compress | METRIC - error 208.67\n",
      "2025-03-14T13:08:01.322773+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:08:01.323513+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T13:08:01.324276+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.26.self_attn.v_proj using 512 samples\n",
      "2025-03-14T13:08:02.436191+0800 | compress | METRIC - time 1.11s\n",
      "2025-03-14T13:08:02.437835+0800 | compress | METRIC - error 1059.43\n",
      "2025-03-14T13:08:02.438822+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:08:02.439612+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T13:08:02.441516+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.26.self_attn.o_proj using 512 samples\n",
      "2025-03-14T13:08:03.640677+0800 | compress | METRIC - time 1.20s\n",
      "2025-03-14T13:08:03.642234+0800 | compress | METRIC - error 73.02\n",
      "2025-03-14T13:08:03.642870+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:08:03.643245+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T13:08:03.644244+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.26.mlp.gate_proj using 512 samples\n",
      "2025-03-14T13:08:05.425346+0800 | compress | METRIC - time 1.78s\n",
      "2025-03-14T13:08:05.427806+0800 | compress | METRIC - error 4059.57\n",
      "2025-03-14T13:08:05.428763+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:08:05.430226+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T13:08:05.431704+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.26.mlp.up_proj using 512 samples\n",
      "2025-03-14T13:08:07.224657+0800 | compress | METRIC - time 1.79s\n",
      "2025-03-14T13:08:07.226771+0800 | compress | METRIC - error 3135.15\n",
      "2025-03-14T13:08:07.228780+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:08:07.230334+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T13:08:07.231473+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.26.mlp.down_proj using 512 samples\n",
      "2025-03-14T13:08:14.867974+0800 | compress | METRIC - time 7.64s\n",
      "2025-03-14T13:08:14.873219+0800 | compress | METRIC - error 1355.51\n",
      "2025-03-14T13:08:14.874267+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:08:14.874913+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(27/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 151.96it/s]\n",
      "(28/29): Calibrating: 100%|██████████| 512/512 [00:32<00:00, 15.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T13:08:50.649161+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.27.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T13:08:51.936140+0800 | compress | METRIC - time 1.28s\n",
      "2025-03-14T13:08:51.937848+0800 | compress | METRIC - error 1649.36\n",
      "2025-03-14T13:08:51.938544+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:08:51.939091+0800 | compress | METRIC - Compressed module size: 25.708032 MB\n",
      "2025-03-14T13:08:51.940203+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.27.self_attn.k_proj using 512 samples\n",
      "2025-03-14T13:08:53.035737+0800 | compress | METRIC - time 1.10s\n",
      "2025-03-14T13:08:53.037154+0800 | compress | METRIC - error 201.83\n",
      "2025-03-14T13:08:53.038205+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:08:53.038905+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T13:08:53.040644+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.27.self_attn.v_proj using 512 samples\n",
      "2025-03-14T13:08:54.136834+0800 | compress | METRIC - time 1.10s\n",
      "2025-03-14T13:08:54.139102+0800 | compress | METRIC - error 1640.27\n",
      "2025-03-14T13:08:54.139969+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:08:54.140657+0800 | compress | METRIC - Compressed module size: 3.672576 MB\n",
      "2025-03-14T13:08:54.142166+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.27.self_attn.o_proj using 512 samples\n",
      "2025-03-14T13:08:55.334040+0800 | compress | METRIC - time 1.19s\n",
      "2025-03-14T13:08:55.335854+0800 | compress | METRIC - error 94.92\n",
      "2025-03-14T13:08:55.337497+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:08:55.338241+0800 | compress | METRIC - Compressed module size: 25.700864 MB\n",
      "2025-03-14T13:08:55.339771+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.27.mlp.gate_proj using 512 samples\n",
      "2025-03-14T13:08:56.860749+0800 | compress | METRIC - time 1.52s\n",
      "2025-03-14T13:08:56.862476+0800 | compress | METRIC - error 8149.12\n",
      "2025-03-14T13:08:56.864244+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:08:56.865030+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T13:08:56.866495+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.27.mlp.up_proj using 512 samples\n",
      "2025-03-14T13:08:58.371762+0800 | compress | METRIC - time 1.50s\n",
      "2025-03-14T13:08:58.373527+0800 | compress | METRIC - error 3390.82\n",
      "2025-03-14T13:08:58.374432+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:08:58.375121+0800 | compress | METRIC - Compressed module size: 135.847424 MB\n",
      "2025-03-14T13:08:58.377022+0800 | on_sequential_batch_end | INFO - Quantizing model.layers.27.mlp.down_proj using 512 samples\n",
      "2025-03-14T13:09:06.941859+0800 | compress | METRIC - time 8.56s\n",
      "2025-03-14T13:09:06.947603+0800 | compress | METRIC - error 4115.02\n",
      "2025-03-14T13:09:06.948453+0800 | compress | METRIC - GPU 0 | usage: 27.53% | total memory: 85 GB\n",
      "2025-03-14T13:09:06.948862+0800 | compress | METRIC - Compressed module size: 135.801344 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(28/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 134.64it/s]\n",
      "(29/29): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 167.17it/s]\n",
      "(29/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 166.50it/s]\n",
      "manager stage: Modifiers initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T13:09:16.906442+0800 | initialize | INFO - Compression lifecycle initialized for 1 modifiers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manager stage: Modifiers finalized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T13:09:16.910122+0800 | finalize | INFO - Compression lifecycle finalized for 1 modifiers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking whether model follows 2:4 sparsity structure: 100%|██████████| 197/197 [00:15<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14T13:11:06.663747+0800 | get_model_compressor | INFO - Inferring a sparsity configuration requires a global sparsity calculation. This can be costly for large models. To skip the calculation of compression statistics set skip_compression_stats=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating model sparsity: 100%|██████████| 731/731 [00:11<00:00, 63.85it/s]\n",
      "Calculating quantization compression ratio: 284it [00:00, 428.08it/s]\n",
      "Quantized Compression: 100%|██████████| 731/731 [00:07<00:00, 100.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('root-W8A8-Dynamic-Per-Token/tokenizer_config.json',\n",
       " 'root-W8A8-Dynamic-Per-Token/special_tokens_map.json',\n",
       " 'root-W8A8-Dynamic-Per-Token/vocab.json',\n",
       " 'root-W8A8-Dynamic-Per-Token/merges.txt',\n",
       " 'root-W8A8-Dynamic-Per-Token/added_tokens.json',\n",
       " 'root-W8A8-Dynamic-Per-Token/tokenizer.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llmcompressor.transformers import oneshot\n",
    "from llmcompressor.modifiers.quantization import GPTQModifier\n",
    "from llmcompressor.modifiers.smoothquant import SmoothQuantModifier\n",
    "\n",
    "# Configure the quantization algorithms\n",
    "recipe = [\n",
    "    SmoothQuantModifier(smoothing_strength=0.8),\n",
    "    GPTQModifier(targets=\"Linear\", scheme=\"W8A8\", ignore=[\"lm_head\"]),\n",
    "]\n",
    "\n",
    "# Apply quantization\n",
    "oneshot(\n",
    "    model=model,\n",
    "    dataset=ds,\n",
    "    recipe=recipe,\n",
    "    max_seq_length=MAX_SEQUENCE_LENGTH,\n",
    "    num_calibration_samples=NUM_CALIBRATION_SAMPLES,\n",
    ")\n",
    "\n",
    "# Save the compressed model\n",
    "SAVE_DIR = MODEL_ID.split(\"/\")[1] + \"-W8A8-Dynamic-Per-Token\"\n",
    "model.save_pretrained(SAVE_DIR, save_compressed=True)\n",
    "tokenizer.save_pretrained(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7639fb895b38d1d6",
   "metadata": {},
   "source": [
    "### Evaluating Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b21713b-ad2c-4695-980b-6986a5c9ab2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Collecting lm-eval\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/c3/0b/36d6117f644f3685e6b87005ecd7051d01e9cdcf617e8e671102c1546de2/lm_eval-0.4.8-py3-none-any.whl (3.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: accelerate>=0.26.0 in /root/miniconda3/lib/python3.12/site-packages (from lm-eval) (1.5.1)\n",
      "Collecting evaluate (from lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/a2/e7/cbca9e2d2590eb9b5aa8f7ebabe1beb1498f9462d2ecede5c9fd9735faaf/evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: datasets>=2.16.0 in /root/miniconda3/lib/python3.12/site-packages (from lm-eval) (3.3.2)\n",
      "Collecting jsonlines (from lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/f8/62/d9ba6323b9202dd2fe166beab8a86d29465c41a0288cbe229fac60c1ab8d/jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Collecting numexpr (from lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/7d/9c/6b671dd3fb67d7e7da93cb76b7c5277743f310a216b7856bb18776bb3371/numexpr-2.10.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (400 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.6/400.6 kB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting peft>=0.2.0 (from lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/88/05/e58e3aaa36544d30a917814e336fc65a746f708e5874945e92999bc22fa3/peft-0.14.0-py3-none-any.whl (374 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pybind11>=2.6.2 in /root/miniconda3/lib/python3.12/site-packages (from lm-eval) (2.13.6)\n",
      "Collecting pytablewriter (from lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/21/4c/c199512f01c845dfe5a7840ab3aae6c60463b5dc2a775be72502dfd9170a/pytablewriter-1.2.1-py3-none-any.whl (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rouge-score>=0.0.4 (from lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/e2/c5/9136736c37022a6ad27fea38f3111eb8f02fe75d067f9a985cc358653102/rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sacrebleu>=1.5.0 (from lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/cd/45/7b55a7bd7e5c5b573b40ad58ba43fa09962dc5c8d71b1f573d4aeaa54a7e/sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn>=0.24.1 (from lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/29/7a/8bce8968883e9465de20be15542f4c7e221952441727c4dad24d534c6d99/scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m131.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sqlitedict (from lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/12/9a/7620d1e9dcb02839ed6d4b14064e609cdd7a8ae1e47289aa0456796dd9ca/sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.8 in /root/miniconda3/lib/python3.12/site-packages (from lm-eval) (2.5.1)\n",
      "Collecting tqdm-multiprocess (from lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/25/7e/0d889fc6c84e3df6b69aaafe893fc77f69b3d968ac9ce574d1c62c688050/tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: transformers>=4.1 in /root/miniconda3/lib/python3.12/site-packages (from lm-eval) (4.49.0)\n",
      "Requirement already satisfied: zstandard in /root/miniconda3/lib/python3.12/site-packages (from lm-eval) (0.22.0)\n",
      "Requirement already satisfied: dill in /root/miniconda3/lib/python3.12/site-packages (from lm-eval) (0.3.8)\n",
      "Collecting word2number (from lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip (9.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting more_itertools (from lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/23/62/0fe302c6d1be1c777cab0616e6302478251dfbf9055ad426f5d0def75c89/more_itertools-10.6.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<3.0.0,>=1.17 in /root/miniconda3/lib/python3.12/site-packages (from accelerate>=0.26.0->lm-eval) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/lib/python3.12/site-packages (from accelerate>=0.26.0->lm-eval) (23.2)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/lib/python3.12/site-packages (from accelerate>=0.26.0->lm-eval) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /root/miniconda3/lib/python3.12/site-packages (from accelerate>=0.26.0->lm-eval) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /root/miniconda3/lib/python3.12/site-packages (from accelerate>=0.26.0->lm-eval) (0.29.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /root/miniconda3/lib/python3.12/site-packages (from accelerate>=0.26.0->lm-eval) (0.5.3)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/lib/python3.12/site-packages (from datasets>=2.16.0->lm-eval) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /root/miniconda3/lib/python3.12/site-packages (from datasets>=2.16.0->lm-eval) (19.0.1)\n",
      "Requirement already satisfied: pandas in /root/miniconda3/lib/python3.12/site-packages (from datasets>=2.16.0->lm-eval) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /root/miniconda3/lib/python3.12/site-packages (from datasets>=2.16.0->lm-eval) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /root/miniconda3/lib/python3.12/site-packages (from datasets>=2.16.0->lm-eval) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /root/miniconda3/lib/python3.12/site-packages (from datasets>=2.16.0->lm-eval) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /root/miniconda3/lib/python3.12/site-packages (from datasets>=2.16.0->lm-eval) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /root/miniconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.16.0->lm-eval) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /root/miniconda3/lib/python3.12/site-packages (from datasets>=2.16.0->lm-eval) (3.11.13)\n",
      "Requirement already satisfied: absl-py in /root/miniconda3/lib/python3.12/site-packages (from rouge-score>=0.0.4->lm-eval) (2.1.0)\n",
      "Collecting nltk (from rouge-score>=0.0.4->lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/4d/66/7d9e26593edda06e8cb531874633f7c2372279c3b0f46235539fe546df8b/nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m135.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /root/miniconda3/lib/python3.12/site-packages (from rouge-score>=0.0.4->lm-eval) (1.16.0)\n",
      "Collecting portalocker (from sacrebleu>=1.5.0->lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/f7/60/1974cfdd5bb770568ddc6f89f3e0df4cfdd1acffd5a609dff5e95f48c6e2/portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: regex in /root/miniconda3/lib/python3.12/site-packages (from sacrebleu>=1.5.0->lm-eval) (2024.11.6)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu>=1.5.0->lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/40/44/4a5f08c96eb108af5cb50b41f76142f0afa346dfa99d5296fe7202a11854/tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting colorama (from sacrebleu>=1.5.0->lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/d1/d6/3965ed04c63042e047cb6a3e6ed1a63a35087b6a609aa3a15ed8ac56c221/colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: lxml in /root/miniconda3/lib/python3.12/site-packages (from sacrebleu>=1.5.0->lm-eval) (5.3.1)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn>=0.24.1->lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/c0/53/eaada1a414c026673eb983f8b4a55fe5eb172725d33d62c1b21f63ff6ca4/scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn>=0.24.1->lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=3.1.0 (from scikit-learn>=0.24.1->lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/32/d5/f9a850d79b0851d1d4ef6456097579a9005b31fea68726a4ae5f2d82ddd9/threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (4.12.2)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (3.3)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (76.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.8->lm-eval) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.8->lm-eval) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/miniconda3/lib/python3.12/site-packages (from transformers>=4.1->lm-eval) (0.21.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /root/miniconda3/lib/python3.12/site-packages (from jsonlines->lm-eval) (23.2.0)\n",
      "Collecting DataProperty<2,>=1.1.0 (from pytablewriter->lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/21/c2/e12e95e289e6081a40454199ab213139ef16a528c7c86432de545b05a23a/DataProperty-1.1.0-py3-none-any.whl (27 kB)\n",
      "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/30/ac/5ce64a1d4cce00390beab88622a290420401f1cabf05caf2fc0995157c21/mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)\n",
      "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/50/14/c5a0e1a947909810fc4c043b84cac472b70e438148d34f5393be1bac663f/pathvalidate-3.2.3-py3-none-any.whl (24 kB)\n",
      "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/08/64/fa4160151976ee4b2cf0c1217a99443ffaeb991956feddfeac9eee9952f8/tabledata-1.3.4-py3-none-any.whl (11 kB)\n",
      "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/05/a2/ed023f2edd1e011b4d99b6727bce8253842d66c3fbf9ed0a26fc09a92571/tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)\n",
      "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/ee/31/e393c3830bdedd01735bd195c85ac3034b6bcaf6c18142bab60a4047ca36/typepy-1.3.4-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /root/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.16.0->lm-eval) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.16.0->lm-eval) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.16.0->lm-eval) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.16.0->lm-eval) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.16.0->lm-eval) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.16.0->lm-eval) (1.18.3)\n",
      "Requirement already satisfied: chardet<6,>=3.0.4 in /root/miniconda3/lib/python3.12/site-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval) (5.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /root/miniconda3/lib/python3.12/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2018.9 in /root/miniconda3/lib/python3.12/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval) (2025.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/lib/python3.12/site-packages (from jinja2->torch>=1.8->lm-eval) (2.1.5)\n",
      "Requirement already satisfied: click in /root/miniconda3/lib/python3.12/site-packages (from nltk->rouge-score>=0.0.4->lm-eval) (8.1.8)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/lib/python3.12/site-packages (from pandas->datasets>=2.16.0->lm-eval) (2025.1)\n",
      "Building wheels for collected packages: rouge-score, sqlitedict, word2number\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24987 sha256=501acd3001cc75ab2d6c64ee307069a066d6c8a4efd303c771566c95859315f4\n",
      "  Stored in directory: /root/.cache/pip/wheels/b4/5c/8c/1db861e2b281d70ba4f03bbb6d21a7764db32456cc93398bd0\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16926 sha256=065f38219b7a60f4eecf9ac3f61399217a09a8a624e8b52971faf7f86708aceb\n",
      "  Stored in directory: /root/.cache/pip/wheels/a0/73/fe/f83fcbe3252c569dcc0e2fb29fd099d096a16eacc99bafa2d8\n",
      "  Building wheel for word2number (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5625 sha256=38135fb983553d2471e929f7df3011cd3fd009ea28f3e9334fb484a886c84e1c\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/cd/f8/76058f3da0e2062eb6a5189484562766d81dad54c670fa3b7c\n",
      "Successfully built rouge-score sqlitedict word2number\n",
      "Installing collected packages: word2number, sqlitedict, threadpoolctl, tcolorpy, tabulate, scipy, portalocker, pathvalidate, numexpr, more_itertools, mbstrdecoder, jsonlines, joblib, colorama, typepy, tqdm-multiprocess, scikit-learn, sacrebleu, nltk, rouge-score, DataProperty, tabledata, peft, evaluate, pytablewriter, lm-eval\n",
      "Successfully installed DataProperty-1.1.0 colorama-0.4.6 evaluate-0.4.3 joblib-1.4.2 jsonlines-4.0.0 lm-eval-0.4.8 mbstrdecoder-1.1.4 more_itertools-10.6.0 nltk-3.9.1 numexpr-2.10.2 pathvalidate-3.2.3 peft-0.14.0 portalocker-3.1.1 pytablewriter-1.2.1 rouge-score-0.1.2 sacrebleu-2.5.1 scikit-learn-1.6.1 scipy-1.15.2 sqlitedict-2.1.0 tabledata-1.3.4 tabulate-0.9.0 tcolorpy-0.1.7 threadpoolctl-3.6.0 tqdm-multiprocess-0.0.11 typepy-1.3.4 word2number-1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install lm-eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bf2234bbeb5aa91",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2781918001.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    lm_eval --model vllm \\\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "lm_eval --model vllm   --model_args pretrained=\"/root/autodl-fs/data2/anti_fraud/models/modelscope/hub/hub/Qwen2-7B-Instruct-W8A8-Dynamic-Per-Token\",add_bos_token=true   --tasks gsm8k   --num_fewshot 5   --limit 250   --batch_size 'auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72238f8e-533f-4c92-8887-10dcabb4cb8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
