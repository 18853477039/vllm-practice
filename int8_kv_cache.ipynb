{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "# !pip install llmcompressor"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading the Model",
   "id": "c19034502bae1d7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "MODEL_ID = \"Qwen/Qwen2-7B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID, device_map=\"auto\", torch_dtype=\"auto\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)"
   ],
   "id": "f3170c095eb36baf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Preparing Calibration Data",
   "id": "cd7bfbd60029dbc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "NUM_CALIBRATION_SAMPLES = 512\n",
    "MAX_SEQUENCE_LENGTH = 2048\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "# TODO use chinese dataset\n",
    "ds = load_dataset(\"HuggingFaceH4/ultrachat_200k\", split=\"train_sft\")\n",
    "ds = ds.shuffle(seed=42).select(range(NUM_CALIBRATION_SAMPLES))\n",
    "\n",
    "def preprocess(example):\n",
    "    return {\"text\": tokenizer.apply_chat_template(example[\"messages\"], tokenize=False)}\n",
    "ds = ds.map(preprocess)\n",
    "\n",
    "def tokenize(sample):\n",
    "    return tokenizer(sample[\"text\"], padding=False, max_length=MAX_SEQUENCE_LENGTH, truncation=True, add_special_tokens=False)\n",
    "ds = ds.map(tokenize, remove_columns=ds.column_names)"
   ],
   "id": "91972af9a3dfef80"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Applying Quantization",
   "id": "2c6aec571fb8e9f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from llmcompressor.transformers import oneshot\n",
    "from llmcompressor.modifiers.quantization import GPTQModifier\n",
    "from llmcompressor.modifiers.smoothquant import SmoothQuantModifier\n",
    "\n",
    "# Configure the quantization algorithms\n",
    "recipe = [\n",
    "    SmoothQuantModifier(smoothing_strength=0.8),\n",
    "    GPTQModifier(targets=\"Linear\", scheme=\"W8A8\", ignore=[\"lm_head\"]),\n",
    "]\n",
    "\n",
    "# Apply quantization\n",
    "oneshot(\n",
    "    model=model,\n",
    "    dataset=ds,\n",
    "    recipe=recipe,\n",
    "    max_seq_length=MAX_SEQUENCE_LENGTH,\n",
    "    num_calibration_samples=NUM_CALIBRATION_SAMPLES,\n",
    ")\n",
    "\n",
    "# Save the compressed model\n",
    "SAVE_DIR = MODEL_ID.split(\"/\")[1] + \"-W8A8-Dynamic-Per-Token\"\n",
    "model.save_pretrained(SAVE_DIR, save_compressed=True)\n",
    "tokenizer.save_pretrained(SAVE_DIR)"
   ],
   "id": "11489231bd209ea5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluating Accuracy",
   "id": "7639fb895b38d1d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# lm_eval --model vllm \\\n",
    "#   --model_args pretrained=\"/Qwen/Qwen2-7B-Instruct-W8A8-Dynamic-Per-Token\",add_bos_token=true \\\n",
    "#   --tasks gsm8k \\\n",
    "#   --num_fewshot 5 \\\n",
    "#   --limit 250 \\\n",
    "#   --batch_size 'auto'"
   ],
   "id": "3bf2234bbeb5aa91"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
